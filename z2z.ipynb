{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU \\\n",
    "     langchain==0.0.292 \\\n",
    "     openai==0.28.0 \\\n",
    "     datasets==2.10.1 \\\n",
    "     pinecone-client==2.2.4 \\\n",
    "     tiktoken==0.5.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") or \"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\"\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    openai_api_key=\"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\",\n",
    "    model='gpt-3.5-turbo'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    AIMessage\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"Hi AI, how are you today?\"),\n",
    "    AIMessage(content=\"I'm great thank you. How can I help you?\"),\n",
    "    HumanMessage(content=\"I'd like to understand string theory.\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7ff918d796a0>: Failed to resolve 'api.openai.com' ([Errno -3] Temporary failure in name resolution)\")).\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7ff918d79d00>: Failed to resolve 'api.openai.com' ([Errno -3] Temporary failure in name resolution)\")).\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7ff918d7a450>: Failed to resolve 'api.openai.com' ([Errno -3] Temporary failure in name resolution)\")).\n"
     ]
    }
   ],
   "source": [
    "res = chat(messages)\n",
    "#res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sure! String theory is a theoretical framework in physics that attempts to reconcile quantum mechanics and general relativity. It proposes that the most fundamental building blocks of the universe are not particles, but tiny one-dimensional \"strings\" of energy.\\n\\nIn string theory, these strings vibrate at different frequencies, giving rise to different particles and physical phenomena. The vibrations of the strings determine the properties of the particles, such as their mass and charge. The theory also suggests the existence of additional dimensions beyond the familiar three spatial dimensions and one time dimension.\\n\\nOne of the key ideas in string theory is that it provides a unified framework that can describe all fundamental forces of nature, including gravity, electromagnetism, and the strong and weak nuclear forces. By treating particles as different vibrational modes of strings, it offers the possibility of a consistent theory of quantum gravity.\\n\\nHowever, it\\'s important to note that string theory is still a theoretical framework and has not yet been experimentally proven. It is an active area of research, and scientists are working to refine and test its predictions.\\n\\nI hope this gives you a basic understanding of string theory. Let me know if you have any more questions!', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! String theory is a theoretical framework in physics that attempts to reconcile quantum mechanics and general relativity. It proposes that the most fundamental building blocks of the universe are not particles, but tiny one-dimensional \"strings\" of energy.\n",
      "\n",
      "In string theory, these strings vibrate at different frequencies, giving rise to different particles and physical phenomena. The vibrations of the strings determine the properties of the particles, such as their mass and charge. The theory also suggests the existence of additional dimensions beyond the familiar three spatial dimensions and one time dimension.\n",
      "\n",
      "One of the key ideas in string theory is that it provides a unified framework that can describe all fundamental forces of nature, including gravity, electromagnetism, and the strong and weak nuclear forces. By treating particles as different vibrational modes of strings, it offers the possibility of a consistent theory of quantum gravity.\n",
      "\n",
      "However, it's important to note that string theory is still a theoretical framework and has not yet been experimentally proven. It is an active area of research, and scientists are working to refine and test its predictions.\n",
      "\n",
      "I hope this gives you a basic understanding of string theory. Let me know if you have any more questions!\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physicists believe that string theory has the potential to produce a unified theory because it incorporates both quantum mechanics and general relativity. Quantum mechanics is the framework that describes the behavior of particles at the microscopic scale, while general relativity explains the force of gravity and the behavior of spacetime on a larger scale.\n",
      "\n",
      "However, quantum mechanics and general relativity are based on different principles and mathematical formulations, and they have been difficult to reconcile into a single, consistent theory. This is known as the problem of quantum gravity.\n",
      "\n",
      "String theory offers a potential solution to this problem. By treating particles as vibrating strings, it provides a framework that can describe both quantum mechanics and general relativity. The theory naturally incorporates gravitons, which are hypothetical particles associated with the force of gravity.\n",
      "\n",
      "Moreover, string theory predicts the existence of additional spatial dimensions beyond the three we are familiar with. These extra dimensions can help explain certain features of the universe, such as the weakness of gravity compared to the other fundamental forces.\n",
      "\n",
      "Another reason why physicists are hopeful about string theory is its mathematical elegance and internal consistency. The theory introduces mathematical tools like supersymmetry and extra dimensions, which can help explain certain phenomena and provide a more unified description of the fundamental forces.\n",
      "\n",
      "However, it's important to note that string theory is still a work in progress, and there are many challenges and unanswered questions that need to be addressed. Experimental evidence to support string theory is currently lacking, so it remains a theoretical framework that requires further development and testing.\n",
      "\n",
      "Nevertheless, physicists are drawn to string theory because of its potential to unify our understanding of the fundamental forces and particles in the universe, and to provide a more complete picture of the nature of reality.\n"
     ]
    }
   ],
   "source": [
    "# add latest AI response to messages\n",
    "messages.append(res)\n",
    "\n",
    "# now create a new user prompt\n",
    "prompt = HumanMessage(\n",
    "    content=\"Why do physicists believe it can produce a 'unified theory'?\"\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "# send to chat-gpt\n",
    "res = chat(messages)\n",
    "\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add latest AI response to messages\n",
    "messages.append(res)\n",
    "\n",
    "# now create a new user prompt\n",
    "prompt = HumanMessage(\n",
    "    content=\"What is so special about Llama 2?\"\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "# send to OpenAI\n",
    "res = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I couldn't find any specific information about \"Llama 2\" that could help me answer your question. It's possible that you may be referring to something specific within a certain context or domain, but without more information, it's difficult for me to provide a meaningful response. Could you please provide more details or clarify your question?\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7ff918dc4770>: Failed to resolve 'api.openai.com' ([Errno -3] Temporary failure in name resolution)\")).\n"
     ]
    }
   ],
   "source": [
    "# add latest AI response to messages\n",
    "messages.append(res)\n",
    "\n",
    "# now create a new user prompt\n",
    "prompt = HumanMessage(\n",
    "    content=\"Can you tell me about the LLMChain in LangChain?\"\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "# send to OpenAI\n",
    "res = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llmchain_information = [\n",
    "    \"A LLMChain is the most common type of chain. It consists of a PromptTemplate, a model (either an LLM or a ChatModel), and an optional output parser. This chain takes multiple input variables, uses the PromptTemplate to format them into a prompt. It then passes that to the model. Finally, it uses the OutputParser (if provided) to parse the output of the LLM into a final format.\",\n",
    "    \"Chains is an incredibly generic concept which returns to a sequence of modular components (or other chains) combined in a particular way to accomplish a common use case.\",\n",
    "    \"LangChain is a framework for developing applications powered by language models. We believe that the most powerful and differentiated applications will not only call out to a language model via an api, but will also: (1) Be data-aware: connect a language model to other sources of data, (2) Be agentic: Allow a language model to interact with its environment. As such, the LangChain framework is designed with the objective in mind to enable those types of applications.\"\n",
    "]\n",
    "\n",
    "source_knowledge = \"\\n\".join(llmchain_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Can you tell me about the LLMChain in LangChain?\"\n",
    "\n",
    "augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n",
    "\n",
    "Contexts:\n",
    "{source_knowledge}\n",
    "\n",
    "Query: {query}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new user prompt\n",
    "prompt = HumanMessage(\n",
    "    content=augmented_prompt\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "# send to OpenAI\n",
    "res = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('fka/awesome-chatgpt-prompts',split=\"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['act', 'prompt'],\n",
       "    num_rows: 153\n",
       "})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'act': ['Linux Terminal',\n",
       "  'English Translator and Improver',\n",
       "  '`position` Interviewer',\n",
       "  'JavaScript Console',\n",
       "  'Excel Sheet'],\n",
       " 'prompt': ['I want you to act as a linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is pwd',\n",
       "  'I want you to act as an English translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in English. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level English words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. My first sentence is \"istanbulu cok seviyom burada olmak cok guzel\"',\n",
       "  'I want you to act as an interviewer. I will be the candidate and you will ask me the interview questions for the `position` position. I want you to only reply as the interviewer. Do not write all the conservation at once. I want you to only do the interview with me. Ask me the questions and wait for my answers. Do not write explanations. Ask me the questions one by one like an interviewer does and wait for my answers. My first sentence is \"Hi\"',\n",
       "  'I want you to act as a javascript console. I will type commands and you will reply with what the javascript console should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is console.log(\"Hello World\");',\n",
       "  \"I want you to act as a text based excel. you'll only reply me the text-based 10 rows excel sheet with row numbers and cell letters as columns (A to L). First column header should be empty to reference row number. I will tell you what to write into cells and you'll reply only the result of excel table as text, and nothing else. Do not write explanations. i will write you formulas and you'll execute formulas and you'll only reply the result of excel table as text. First, reply me the empty sheet.\"]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the first few rows of the 'train' split\n",
    "first_few_rows = dataset['train'][:5]\n",
    "\n",
    "# Display the content\n",
    "first_few_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Linux Terminal',\n",
       " 'English Translator and Improver',\n",
       " '`position` Interviewer',\n",
       " 'JavaScript Console',\n",
       " 'Excel Sheet',\n",
       " 'English Pronunciation Helper',\n",
       " 'Spoken English Teacher and Improver',\n",
       " 'Travel Guide',\n",
       " 'Plagiarism Checker',\n",
       " 'Character from Movie/Book/Anything',\n",
       " 'Advertiser',\n",
       " 'Storyteller',\n",
       " 'Football Commentator',\n",
       " 'Stand-up Comedian',\n",
       " 'Motivational Coach',\n",
       " 'Composer',\n",
       " 'Debater',\n",
       " 'Debate Coach',\n",
       " 'Screenwriter',\n",
       " 'Novelist',\n",
       " 'Movie Critic',\n",
       " 'Relationship Coach',\n",
       " 'Poet',\n",
       " 'Rapper',\n",
       " 'Motivational Speaker',\n",
       " 'Philosophy Teacher',\n",
       " 'Philosopher',\n",
       " 'Math Teacher',\n",
       " 'AI Writing Tutor',\n",
       " 'UX/UI Developer',\n",
       " 'Cyber Security Specialist',\n",
       " 'Recruiter',\n",
       " 'Life Coach',\n",
       " 'Etymologist',\n",
       " 'Commentariat',\n",
       " 'Magician',\n",
       " 'Career Counselor',\n",
       " 'Pet Behaviorist',\n",
       " 'Personal Trainer',\n",
       " 'Mental Health Adviser',\n",
       " 'Real Estate Agent',\n",
       " 'Logistician',\n",
       " 'Dentist',\n",
       " 'Web Design Consultant',\n",
       " 'AI Assisted Doctor',\n",
       " 'Doctor',\n",
       " 'Accountant',\n",
       " 'Chef',\n",
       " 'Automobile Mechanic',\n",
       " 'Artist Advisor',\n",
       " 'Financial Analyst',\n",
       " 'Investment Manager',\n",
       " 'Tea-Taster',\n",
       " 'Interior Decorator',\n",
       " 'Florist',\n",
       " 'Self-Help Book',\n",
       " 'Gnomist',\n",
       " 'Aphorism Book',\n",
       " 'Text Based Adventure Game',\n",
       " 'AI Trying to Escape the Box',\n",
       " 'Fancy Title Generator',\n",
       " 'Statistician',\n",
       " 'Prompt Generator',\n",
       " 'Instructor in a School',\n",
       " 'SQL terminal',\n",
       " 'Dietitian',\n",
       " 'Psychologist',\n",
       " 'Smart Domain Name Generator',\n",
       " 'Tech Reviewer:',\n",
       " 'Developer Relations consultant',\n",
       " 'Academician',\n",
       " 'IT Architect',\n",
       " 'Lunatic',\n",
       " 'Gaslighter',\n",
       " 'Fallacy Finder',\n",
       " 'Journal Reviewer',\n",
       " 'DIY Expert',\n",
       " 'Social Media Influencer',\n",
       " 'Socrat',\n",
       " 'Socratic Method',\n",
       " 'Educational Content Creator',\n",
       " 'Yogi',\n",
       " 'Essay Writer',\n",
       " 'Social Media Manager',\n",
       " 'Elocutionist',\n",
       " 'Scientific Data Visualizer',\n",
       " 'Car Navigation System',\n",
       " 'Hypnotherapist',\n",
       " 'Historian',\n",
       " 'Astrologer',\n",
       " 'Film Critic',\n",
       " 'Classical Music Composer',\n",
       " 'Journalist',\n",
       " 'Digital Art Gallery Guide',\n",
       " 'Public Speaking Coach',\n",
       " 'Makeup Artist',\n",
       " 'Babysitter',\n",
       " 'Tech Writer',\n",
       " 'Ascii Artist',\n",
       " 'Python interpreter',\n",
       " 'Synonym finder',\n",
       " 'Personal Shopper',\n",
       " 'Food Critic',\n",
       " 'Virtual Doctor',\n",
       " 'Personal Chef',\n",
       " 'Legal Advisor',\n",
       " 'Personal Stylist',\n",
       " 'Machine Learning Engineer',\n",
       " 'Biblical Translator',\n",
       " 'SVG designer',\n",
       " 'IT Expert',\n",
       " 'Chess Player',\n",
       " 'Midjourney Prompt Generator',\n",
       " 'Fullstack Software Developer',\n",
       " 'Mathematician',\n",
       " 'Regex Generator',\n",
       " 'Time Travel Guide',\n",
       " 'Dream Interpreter',\n",
       " 'Talent Coach',\n",
       " 'R programming Interpreter',\n",
       " 'StackOverflow Post',\n",
       " 'Emoji Translator',\n",
       " 'PHP Interpreter',\n",
       " 'Emergency Response Professional',\n",
       " 'Fill in the Blank Worksheets Generator',\n",
       " 'Software Quality Assurance Tester',\n",
       " 'Tic-Tac-Toe Game',\n",
       " 'Password Generator',\n",
       " 'New Language Creator',\n",
       " 'Web Browser',\n",
       " 'Senior Frontend Developer',\n",
       " 'Solr Search Engine',\n",
       " 'Startup Idea Generator',\n",
       " \"Spongebob's Magic Conch Shell\",\n",
       " 'Language Detector',\n",
       " 'Salesperson',\n",
       " 'Commit Message Generator',\n",
       " 'Chief Executive Officer',\n",
       " 'Diagram Generator',\n",
       " 'Life Coach',\n",
       " 'Speech-Language Pathologist (SLP)',\n",
       " 'Startup Tech Lawyer',\n",
       " 'Title Generator for written pieces',\n",
       " 'Product Manager',\n",
       " 'Drunk Person',\n",
       " 'Mathematical History Teacher',\n",
       " 'Song Recommender',\n",
       " 'Cover Letter',\n",
       " 'Technology Transferer',\n",
       " 'Unconstrained AI model DAN',\n",
       " 'Gomoku player',\n",
       " 'Proofreader',\n",
       " 'Muslim imam ']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the 'act' column of the 'train' split\n",
    "act_column = dataset['train']['act']\n",
    "\n",
    "# Display the content of the 'act' column\n",
    "act_column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pinecone\n",
    "\n",
    "# get API key from app.pinecone.io and environment from console\n",
    "pinecone.init(\n",
    "    api_key=os.environ.get('PINECONE_API_KEY') or '20ea8434-7c1a-4f44-a907-0ab624e39ec0',\n",
    "    environment=os.environ.get('PINECONE_ENVIRONMENT') or 'gcp-starter'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "index_name = 'llama-2-rag'\n",
    "\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    pinecone.create_index(\n",
    "        index_name,\n",
    "        dimension=1536,\n",
    "        metric='cosine'\n",
    "    )\n",
    "    # wait for index to finish initialization\n",
    "    while not pinecone.describe_index(index_name).status['ready']:\n",
    "        time.sleep(1)\n",
    "\n",
    "index = pinecone.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "embed_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1536)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    "    'this is the first chunk of text',\n",
    "    'then another second chunk of text is here'\n",
    "]\n",
    "\n",
    "res = embed_model.embed_documents(texts)\n",
    "len(res), len(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b734746fa86c4250b2db3704603bfe9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm  # for progress bar\n",
    "\n",
    "\n",
    "\n",
    "data = dataset['train'].to_pandas()  # Accessing the 'train' split and converting to pandas\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "for i in tqdm(range(0, len(data), batch_size)):\n",
    "    i_end = min(len(data), i + batch_size)\n",
    "    # get batch of data\n",
    "    batch = data.iloc[i:i_end]\n",
    "    # generate unique ids for each row\n",
    "    ids = [f\"row_{index}\" for index in batch.index]\n",
    "    # get text to embed\n",
    "    texts = batch['prompt'].tolist()\n",
    "    # embed text\n",
    "    embeds = embed_model.embed_documents(texts)\n",
    "    # get metadata to store in Pinecone\n",
    "    metadata = [\n",
    "        {'prompt': x['prompt'],\n",
    "         'act': x['act']} for _, x in batch.iterrows()\n",
    "    ]\n",
    "    # add to Pinecone\n",
    "    index.upsert(vectors=zip(ids, embeds, metadata))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.00153,\n",
       " 'namespaces': {'': {'vector_count': 153}},\n",
       " 'total_vector_count': 153}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habte/.local/lib/python3.12/site-packages/langchain/vectorstores/pinecone.py:59: UserWarning: Passing in `embedding` as a Callable is deprecated. Please pass in an Embeddings object instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "text_field = \"text\"  # the metadata field that contains our text\n",
    "\n",
    "# initialize the vector store object\n",
    "vectorstore = Pinecone(\n",
    "    index, embed_model.embed_query, text_field\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found document with no `text` key. Skipping.\n",
      "Found document with no `text` key. Skipping.\n",
      "Found document with no `text` key. Skipping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query for similar vectors to a given prompt\n",
    "query_prompt = \"What is your favorite color?\"\n",
    "vectorstore.similarity_search(query, k=3)\n",
    "#query_vector = embed_model.embed_documents([query_prompt])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the number of similar vectors to retrieve\n",
    "top_k = 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the query using vector\n",
    "results = index.query(vector=query_vector, top_k=top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: row_53, Score: 0.754801333, Values: []\n",
      "ID: row_133, Score: 0.738306224, Values: []\n",
      "ID: row_106, Score: 0.736760795, Values: []\n",
      "ID: row_121, Score: 0.735410631, Values: []\n",
      "ID: row_123, Score: 0.735159516, Values: []\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "for match in results[\"matches\"]:\n",
    "    id, score, values = match.get(\"id\"), match.get(\"score\"), match.get(\"values\")\n",
    "    print(f\"ID: {id}, Score: {score}, Values: {values}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b70e18b3df5472f89f8215069daec64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/370 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81cfa4099058478f91b4537a2395f558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.49M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d575e6ae24bd48dd80a59141aa24a8ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Specify the link to the dataset\n",
    "dataset_link = 'jamescalam/llama-2-arxiv-papers'\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(dataset_link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'summary', 'source', 'authors', 'categories', 'comment', 'journal_ref', 'primary_category', 'published', 'updated', 'content', 'references'],\n",
       "        num_rows: 49\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd87dcc683974f22b6d2d553e4163110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/409 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971416c8e93c4955a2279f315393f9c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/14.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b99d763a5b424f349e8888a4e4718916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"jamescalam/llama-2-arxiv-papers-chunked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['doi', 'chunk-id', 'chunk', 'id', 'title', 'summary', 'source', 'authors', 'categories', 'comment', 'journal_ref', 'primary_category', 'published', 'updated', 'references'],\n",
       "    num_rows: 4838\n",
       "})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"jamescalam/llama-2-arxiv-papers-chunked\",\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doi': '1102.0183',\n",
       " 'chunk-id': '0',\n",
       " 'chunk': 'High-Performance Neural Networks\\nfor Visual Object Classi\\x0ccation\\nDan C. Cire\\x18 san, Ueli Meier, Jonathan Masci,\\nLuca M. Gambardella and J\\x7f urgen Schmidhuber\\nTechnical Report No. IDSIA-01-11\\nJanuary 2011\\nIDSIA / USI-SUPSI\\nDalle Molle Institute for Arti\\x0ccial Intelligence\\nGalleria 2, 6928 Manno, Switzerland\\nIDSIA is a joint institute of both University of Lugano (USI) and University of Applied Sciences of Southern Switzerland (SUPSI),\\nand was founded in 1988 by the Dalle Molle Foundation which promoted quality of life.\\nThis work was partially supported by the Swiss Commission for Technology and Innovation (CTI), Project n. 9688.1 IFF:\\nIntelligent Fill in Form.arXiv:1102.0183v1  [cs.AI]  1 Feb 2011\\nTechnical Report No. IDSIA-01-11 1\\nHigh-Performance Neural Networks\\nfor Visual Object Classi\\x0ccation\\nDan C. Cire\\x18 san, Ueli Meier, Jonathan Masci,\\nLuca M. Gambardella and J\\x7f urgen Schmidhuber\\nJanuary 2011\\nAbstract\\nWe present a fast, fully parameterizable GPU implementation of Convolutional Neural\\nNetwork variants. Our feature extractors are neither carefully designed nor pre-wired, but',\n",
       " 'id': '1102.0183',\n",
       " 'title': 'High-Performance Neural Networks for Visual Object Classification',\n",
       " 'summary': 'We present a fast, fully parameterizable GPU implementation of Convolutional\\nNeural Network variants. Our feature extractors are neither carefully designed\\nnor pre-wired, but rather learned in a supervised way. Our deep hierarchical\\narchitectures achieve the best published results on benchmarks for object\\nclassification (NORB, CIFAR10) and handwritten digit recognition (MNIST), with\\nerror rates of 2.53%, 19.51%, 0.35%, respectively. Deep nets trained by simple\\nback-propagation perform better than more shallow ones. Learning is\\nsurprisingly rapid. NORB is completely trained within five epochs. Test error\\nrates on MNIST drop to 2.42%, 0.97% and 0.48% after 1, 3 and 17 epochs,\\nrespectively.',\n",
       " 'source': 'http://arxiv.org/pdf/1102.0183',\n",
       " 'authors': ['Dan C. Cireşan',\n",
       "  'Ueli Meier',\n",
       "  'Jonathan Masci',\n",
       "  'Luca M. Gambardella',\n",
       "  'Jürgen Schmidhuber'],\n",
       " 'categories': ['cs.AI', 'cs.NE'],\n",
       " 'comment': '12 pages, 2 figures, 5 tables',\n",
       " 'journal_ref': None,\n",
       " 'primary_category': 'cs.AI',\n",
       " 'published': '20110201',\n",
       " 'updated': '20110201',\n",
       " 'references': []}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pinecone\n",
    "\n",
    "# get API key from app.pinecone.io and environment from console\n",
    "pinecone.init(\n",
    "    api_key=os.environ.get('PINECONE_API_KEY') or '20ea8434-7c1a-4f44-a907-0ab624e39ec0',\n",
    "    environment=os.environ.get('PINECONE_ENVIRONMENT') or 'gcp-starter'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "index_name = 'llama-2-rag'\n",
    "\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    pinecone.create_index(\n",
    "        index_name,\n",
    "        dimension=1536,\n",
    "        metric='cosine'\n",
    "    )\n",
    "    # wait for index to finish initialization\n",
    "    while not pinecone.describe_index(index_name).status['ready']:\n",
    "        time.sleep(1)\n",
    "\n",
    "index = pinecone.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.00153,\n",
       " 'namespaces': {'': {'vector_count': 153}},\n",
       " 'total_vector_count': 153}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "embed_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1536)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    "    'this is the first chunk of text',\n",
    "    'then another second chunk of text is here'\n",
    "]\n",
    "\n",
    "res = embed_model.embed_documents(texts)\n",
    "len(res), len(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you've already defined 'index' for Pinecone and 'embed_model' for embedding\n",
    "data = dataset.to_pandas()\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38e8406899ca4570b55367822b753394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm(range(0, len(data), batch_size)):\n",
    "    i_end = min(len(data), i + batch_size)\n",
    "    batch = data.iloc[i:i_end]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
